{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка двух изображений\n",
    "img1 = cv2.imread(\"images/place.jpg\")\n",
    "h, w, _ = img1.shape\n",
    "#Cлучайная генерация координат для теста\n",
    "x = np.random.randint(0, w - 300) \n",
    "y = np.random.randint(0, h - 200)\n",
    "img2 = img1[y:y+200,x:x+300]\n",
    "\n",
    "# Конвертирование изображений в градации серого\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image 1',img1)\n",
    "cv2.imshow('image 2',img2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание объекта SIFT\n",
    "sift = cv2.SIFT_create(sigma=0.7)\n",
    "\n",
    "# Нахождение ключевых точек и дескрипторов на первом изображении\n",
    "kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "\n",
    "# Нахождение ключевых точек и дескрипторов на втором изображении\n",
    "kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "# Нахождение соответствий между дескрипторами двух изображений\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(des1, des2, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Фильтрация соответствий по лучшим\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    #Методом подбора был найден коэффициент 0.2\n",
    "    if m.distance < 0.2 * n.distance: \n",
    "        good_matches.append(m)\n",
    "\n",
    "img_matches = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imwrite(\"images/Mathces.jpg\", img_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching region: (21, 942, 293, 194)\n",
      "Good job\n",
      "Diff w-x:-4 \n",
      " h-y:-3 \n",
      " w2-x2:3 \n",
      " h2-y2:3\n"
     ]
    }
   ],
   "source": [
    "# Если количество соответствий меньше 4, то считаем, что изображения не связаны\n",
    "if len(good_matches) < 4:\n",
    "    print(\"Images are not connected\")\n",
    "else:\n",
    "    # Нахождение координат ключевых точек в массивах\n",
    "    #Ключевые точки изображения №1\n",
    "    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    #Ключевые точки изображения №2\n",
    "    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Нахождение гомографической матрицы\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Нахождение границы второго изображения на первом изображении\n",
    "    #h, w = img1.shape[:2]\n",
    "    #pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "    #dst = cv2.perspectiveTransform(pts, M)\n",
    "    matching_region = cv2.boundingRect(src_pts)\n",
    "\n",
    "    # Вывод результата\n",
    "    print(\"Matching region:\", matching_region)\n",
    "    cv2.rectangle(img1, (matching_region[0], matching_region[1]),\n",
    "                  (matching_region[0] + matching_region[2], matching_region[1] + matching_region[3]),\n",
    "                  (0, 255, 0), 2)\n",
    "    if abs(x-matching_region[0]) > 0.05*w or \\\n",
    "    abs(y-matching_region[1]) > 0.05*h or \\\n",
    "    abs(x+300-(matching_region[0] + matching_region[2])) > 0.05*w or \\\n",
    "    abs(y+200-(matching_region[1] + matching_region[3])) > 0.05*h:\n",
    "        print(\"Mistakes too big\")\n",
    "    else:\n",
    "        print(\"Good job\")\n",
    "    print(f'Diff \\nw-x:{x-matching_region[0]} \\nh-y:{y-matching_region[1]} \\nw2-x2:{x+300-(matching_region[0] + matching_region[2])} \\nh2-y2:{y+200-(matching_region[1] + matching_region[3])}')\n",
    "    cv2.imshow('resultMatch',img1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows\n",
    "    #cv2.imwrite(\"images/Matching.jpg\", img1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
